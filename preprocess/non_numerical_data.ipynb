{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非数值变量\n",
    "\n",
    "机器学习模型要求输入为数值变量，特征必须是大小为(n_samples, n_features)的数值矩阵，目标是(n_samples, 1)的数值向量。但现实世界的数据集有可能包含非数值数据，例如分类变量，文本数据和图像。\n",
    "\n",
    "这时候需要进行数据预处理（data preprocessing），即采用一些技巧将非数值变量转换为数值变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 分类变量\n",
    "\n",
    "分类变量通常分为两种：有序和无序。\n",
    "\n",
    "* 有序：类别可以相互比较，有大小之分，可以直接转化为数值变量。假设代表收入的变量'income'有3个类别，'low','medium','high'，分别代表低收入，中等收入，高收入，类别是可以直接比较的，并且可以排序，'low' < 'medium' < 'high'。\n",
    "* 无序：类别不可以比较，需要引入虚拟变量(dummy variable)，常用编码技术是独热编码(one-hot encoding)。例如代表性别的变量'gender'有两个类别，'male'和'female'，但'male' < 'female'的关系并不成立。\n",
    "\n",
    "将分类变量转化为数值变量有两种常用方法：标签编码和独热编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 标签编码\n",
    "\n",
    "标签编码(label encoding): 将分类变量的类别编码为数字。\n",
    "\n",
    "用sklearn.preprocessing.LabelEncoder实现，将包含k个类别的分类变量编码为$0,1,2,...(k-1)$\n",
    "\n",
    "标签编码一般不用于特征，而是用于目标变量。\n",
    "\n",
    "假设一个代表性别的特征'gender'，包含两个类别：'male','female'。标签编码将类别编码为整数，0代表男性，1代表女性。但这不符合模型背后的假设，因为机器学习模型认为数据有算数含义，例如0 < 1，这意味着男性 < 女性，但这种关系不成立。**一般会使用独热编码处理分类特征，标签编码仅用于分类目标**。\n",
    "\n",
    "接下来说明如何使用标签编码，假设目标变量代表股票价格趋势，有3种可能的类别，'up','down','range'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  ['down' 'range' 'up']\n",
      "encoded labels:  [2 2 0 1 2 0 1 1 0]\n",
      "inverse encoding:  ['down' 'range' 'up']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 目标变量\n",
    "y = [\"up\", \"up\", \"down\", \"range\", \"up\", \"down\", \"range\", \"range\", \"down\"]\n",
    "\n",
    "# 创建LabelEncoder对象\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 拟合数据\n",
    "le.fit(y)\n",
    "\n",
    "# 查看包含哪些类别\n",
    "print(\"classes: \", le.classes_)\n",
    "\n",
    "# 编码为数字\n",
    "print(\"encoded labels: \", le.transform(y))\n",
    "\n",
    "# 调用inverse_transform实现反向操作\n",
    "print(\"inverse encoding: \", le.inverse_transform([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 独热编码\n",
    "\n",
    "独热编码(one hot encoding): 将包含m个类别的分类变量转化为$n*m$的二元矩阵，n是观测值数量，m是类别数量。\n",
    "\n",
    "假设分类变量'car_type'，表示汽车类型，包含类别(BMW, Tesla, Audi)，独热编码将产生下图的结果，每一个类别都成为一个新的变量/特征，1表示观测值包含该类别，0表示不包含。\n",
    "\n",
    "![one-hot encoding](../pic/one_hot_encoding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn提供OneHotEncoder类实现独热编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  [array(['Audi', 'BMW', 'Tesla'], dtype='<U5')]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "  Audi  BMW Tesla\n",
      "0  0.0  1.0   0.0\n",
      "1  0.0  0.0   1.0\n",
      "2  1.0  0.0   0.0\n",
      "3  0.0  1.0   0.0\n",
      "4  1.0  0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 分类特征\n",
    "car_types = np.array([\"BMW\", \"Tesla\", \"Audi\", \"BMW\", \"Audi\"])\n",
    "\n",
    "# 创建编码器\n",
    "oe = OneHotEncoder()\n",
    "\n",
    "# OneHotEncoder要求输入为二维数组，用reshape重排结构\n",
    "oe.fit(car_types.reshape(-1, 1))\n",
    "\n",
    "# 查看类别\n",
    "print(\"classes: \", oe.categories_)\n",
    "\n",
    "# 调用transform获得编码结果\n",
    "# transform默认返回稀疏矩阵，当分类变量包含很多类别时非常有用，进一步调用toarray可获得熟悉的numpy二维数组\n",
    "# 创建OneHotEncoder实例时，如果设置sparse=False，调用transform会得到二维数组\n",
    "encoded_labels = oe.transform(car_types.reshape(-1, 1)).toarray()\n",
    "print(encoded_labels)\n",
    "\n",
    "# 用数据框展现最终的结果，便于理解\n",
    "encoded_labels_df = pd.DataFrame(encoded_labels, columns=oe.categories_)\n",
    "print(encoded_labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用pd.get_dummies实现独热编码，这比sklearn的接口更方便，因为它允许我们直接操作数据框。\n",
    "\n",
    "pd.get_dummies默认将数据类型为'object'的变量视为分类变量，也可以提供要编码的变量名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car_type\n",
      "0      BMW\n",
      "1    Tesla\n",
      "2     Audi\n",
      "3      BMW\n",
      "4     Audi\n",
      "   car_type_Audi  car_type_BMW  car_type_Tesla\n",
      "0              0             1               0\n",
      "1              0             0               1\n",
      "2              1             0               0\n",
      "3              0             1               0\n",
      "4              1             0               0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_types = pd.DataFrame({\"car_type\": [\"BMW\", \"Tesla\", \"Audi\", \"BMW\", \"Audi\"]})\n",
    "print(car_types)\n",
    "\n",
    "car_types_encoded = pd.get_dummies(car_types)\n",
    "print(car_types_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 虚拟变量陷阱\n",
    "\n",
    "独热编码会引入K个新特征，分别表示分类变量的K个类别。但如果我们使用回归模型，则不能这么做，因为这会导致多重共线性。\n",
    "\n",
    "首先我们要理解两个新的概念：**虚拟变量陷阱**和**多重共线性**。\n",
    "\n",
    "虚拟变量陷阱：在回归模型中，虚拟变量(dummy variable)用于表示分类变量的类别，通常用1和0表示。例如性别变量'gender'有两个类别，分别是男性和女性，那么可以引入**一个虚拟变量D**，如果观测值是男性记为1，否则记为0。**如果分类变量有$k$个类别，引入$(k-1)$个虚拟变量，有一个类别作为基准组/参照组**。如果引入$k$个虚拟变量，会导致多重共线性。\n",
    "\n",
    "多重共线性：如果1个自变量可以表示为其它自变量的线性组合，就是完全多重共线性，无法估计回归方程的斜率系数。简单理解就是预测变量(特征)之间高度相关。\n",
    "\n",
    "假设变量$X$有3个类别，引入3个虚拟变量$X_a, X_b, X_c$，每个变量的取值都是1或0，则必然满足以下关系：$X_a + X_b + X_c = 1$，那么任何一个变量都可以表示为其余两个虚拟变量的线性组合，结果就是完全多重共线性。\n",
    "\n",
    "[独热编码和多重共线性](https://geoffruddock.com/one-hot-encoding-plus-linear-regression-equals-multi-collinearity/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用OneHotEncoder创建(k-1)个虚拟变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features drop:  ['Audi']\n",
      "features retain:  ['BMW' 'Tesla']\n",
      "   BMW  Tesla  class\n",
      "0  1.0    0.0    BMW\n",
      "1  0.0    1.0  Tesla\n",
      "2  0.0    0.0   Audi\n",
      "3  1.0    0.0    BMW\n",
      "4  0.0    0.0   Audi\n"
     ]
    }
   ],
   "source": [
    "car_types = np.array([\"BMW\", \"Tesla\", \"Audi\", \"BMW\", \"Audi\"])\n",
    "\n",
    "# 将第一个类别作为参照组\n",
    "oe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "# 拟合数据\n",
    "oe.fit(car_types.reshape(-1, 1))\n",
    "\n",
    "# 编码\n",
    "encoded_labels = oe.transform(car_types.reshape(-1, 1)).toarray()\n",
    "\n",
    "# 查看剔除的特征\n",
    "# oe.categories_保存了所有的类别，包括剔除的类别\n",
    "# oe.drop_idx_保存了categories_中被剔除类别的索引\n",
    "features_drop = oe.categories_[0][oe.drop_idx_.astype(int)]\n",
    "features_retain = np.delete(oe.categories_[0], oe.drop_idx_.astype(int))\n",
    "print(\"features drop: \", features_drop)\n",
    "print(\"features retain: \", features_retain)\n",
    "\n",
    "# 查看结果\n",
    "encoded_labels_df = pd.DataFrame(encoded_labels, columns=features_retain)\n",
    "encoded_labels_df[\"class\"] = car_types\n",
    "print(encoded_labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用pd.get_dummies创建(k-1)个虚拟变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car_type  car_type_BMW  car_type_Tesla\n",
      "0      BMW             1               0\n",
      "1    Tesla             0               1\n",
      "2     Audi             0               0\n",
      "3      BMW             1               0\n",
      "4     Audi             0               0\n"
     ]
    }
   ],
   "source": [
    "car_types = pd.DataFrame({\"car_type\": [\"BMW\", \"Tesla\", \"Audi\", \"BMW\", \"Audi\"]})\n",
    "\n",
    "# drop_first=True: 将第一个类别作为参照组\n",
    "car_types_encode = pd.get_dummies(car_types, drop_first=True)\n",
    "\n",
    "# 查看结果\n",
    "car_types_join = pd.concat([car_types, car_types_encode], axis=1)\n",
    "print(car_types_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 文本数据\n",
    "\n",
    "有时候模型的输入是文本数据，例如新闻，社交媒体发言等，需要把文本转化为数值矩阵。\n",
    "\n",
    "常用处理方法有两种：\n",
    "\n",
    "1. 单词统计(word counts): 统计每个单词出现的次数。\n",
    "2. TF-IDF(Term Frequency-Inverse Document Frequency): 统计单词出现的“频率”。\n",
    "\n",
    "单词统计法的缺陷是当单词出现次数较多，模型会赋予更多的权重，Tfidf可以规避这个缺陷。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 word counts\n",
    "\n",
    "行代表观测值，列(特征)是所有文档中出现过的单词，特征值表示单词在当前文档中出现的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>problem of evil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>evil queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>horizon problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evil  horizon  of  problem  queen             text\n",
       "0     1        0   1        1      0  problem of evil\n",
       "1     1        0   0        0      1       evil queen\n",
       "2     0        1   0        1      0  horizon problem"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# 准备3个观测值，文本变量\n",
    "sample = ['problem of evil',\n",
    "          'evil queen',\n",
    "          'horizon problem']\n",
    "\n",
    "# 创建Vectorizer对象，调用fit_transform方法，返回稀疏矩阵(sparse matrix)\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "\n",
    "# 将结果转化为数据框，以更直观的方式显示结果\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "df[\"text\"] = sample\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tfidf\n",
    "\n",
    "行代表观测值，列(特征)是所有文档出现过的单词，分数是文档中词的频率乘以所有文档的逆频率，分数越高显示单词在当前文档中使用越多，而在其它文档中使用得越少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evil</th>\n",
       "      <th>horizon</th>\n",
       "      <th>of</th>\n",
       "      <th>problem</th>\n",
       "      <th>queen</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>problem of evil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>evil queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>horizon problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       evil   horizon        of   problem     queen             text\n",
       "0  0.517856  0.000000  0.680919  0.517856  0.000000  problem of evil\n",
       "1  0.605349  0.000000  0.000000  0.000000  0.795961       evil queen\n",
       "2  0.000000  0.795961  0.000000  0.605349  0.000000  horizon problem"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "df[\"text\"] = sample\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyds",
   "language": "python",
   "name": "pyds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
